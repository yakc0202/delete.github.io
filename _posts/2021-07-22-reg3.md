---
title: "다중 선형 회귀"
date: 2021-07-21 -0400
categories:
 - Regression
tags: 
 - [데이터 청년 캠퍼스, Regression]

toc: true
---
## 보스턴 집값 데이터셋을 이용한 다중 선형 회귀 모델 구축 및 평가  
```py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
```  

- 데이터 수집  
  ```py
  from skelearn.datasets import load_boston
  boston = load_boston()
  ```  

- 데이터 이해
  - 데이터셋 정보 확인
    ```py
    boston.feature_names
    ```  
    <div class="notice" markdown="1">
    CRIM: 타운(지역)별 범죄 발생률  
    ZN: 25,000평방 피트를 초과하는 거주 지역 비율  
    INDUS: 비소매 상업 지역의 토지 비율  
    CHAS: 찰스강의 더미 변수(1은 강의 경계, 0은 경계 아님) - 카테고리 변수  
    NOX: 일산화질소 농도(10밀리온)  
    RM: 거주할 수 있는 방의 개수  
    AGE: 1940년 이전에 건축된 주택 비율  
    DIS: 5개 주요 고용센터까지 가중 거리  
    RAD: 고속도로 접근 용이도  
    TAX: 10,000달러당 재산세 비율  
    PTRATIO: 지역(타운별)의 교사와 학생 수 비율  
    B: 지역의 흑인 거주 비율  
    LSTAT: 모집단의 하위 계층의 비율  
    PRICE(MEDV): 소유자가 거주하는 주택 가격의 중앙값(단위, 1000달러)  
    </div>  
    
    ```py
    boston.target
    ```  
    
  - 독립변수(feature)와 종속변수를 DataFrame 자료형으로 반환  
    ```py
    boston_df = pd.DataFrame(boston.data, columns = boston.feature_names)
    ```  
    
  - 데이터셋 객체의 target배열(boston.target)을 종속 변수인 주택 가격("PRICE")컬럼으로 추가  
    ```py
    boston_df['PRICE'] = boston.target
    ```  
    
  - 데이터의 크기와 형태를 확인  
    ```py
    boston_df.shape
    ```    
  
  - 데이터 선정 및 분포 정보 확인  
    - CHAS → 연속형 값이 아닌 카테고리형 → 분석 대상에서 제외
      ```py
      boston_df.drop(['CHAS'], axis = 1, inplace = True)
      ```  
      
  - 데이터프레임 정보  
    ```py
    boston_df.info()
    ```

- 데이터 탐색
  - 독립변수와 종속변수와의 관계에 대한 산점도 시각화  
    ```py
    fig, axs = plt.subplots(figsize = (16,12), nrows = 3, ncols = 4)
    
    x_features = ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE',
                  'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']
    
    for i, feature in enumerate(x_features):
        row = int(i / 4)
        col = i % 4
        
        sns.regplot(x = feature, y = "PRICE", data = boston_df, ax = axs[row][col])
    ```  
    
  - 컬럼별로 독립변수들 간의 상관관계 시각화  
    ```py
    ccol = ['INDUS', 'LSTAT', 'RM', 'PRICE']
    
    sns.pairplt(boston_df[ccol])
    ```  
  
  - 선택한 변수들 간의 상관계수 확인  
    ```py
    corrs = boston_df[ccol].corr()
    ```  
  
  - 컬럼별로 독립변수간의 상관관계 히트맵 시각화  
    ```py
    sns.heatmap(corrs, annot = True, annot_kws = {'size':13}
    ```  
    
## 보스턴 집값 다중선형 회귀 분석(사이킷런)
- 데이터 분할  
  ```py
  from sklearn.model_selection import train_test_split
  
  X = boston_df.drop(['PRICE'], axis = 1)
  y = boston_df['PRICE']
  
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_split = 0.3, rnadom_state = 42)
  ```  
  
- 모델 클래스 선택  
  ```py
  from sklearn.linear_model import LinearRegression
  
  reg = LinearRegression()
  ```  

- 학습 수행  
  ```py
  reg.fit(X_train, y_train)
  ```  
  
- 모델 평가  
  - 평가(검증)데이터로 예측 수행 → 예측 결과(y_pred)구하기
    ```py
    from sklearn.metrics import mean_squared_error, r2score
    y_pred = reg.predict(X_test)
    ```  
    
  - 평가 지표 계산  
    ```py
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    
    r2 = r2_score(y_test, y_pred)
    ```  
    
  - 수정된 결정 계수 확인(Adjusted-R2)
    ```py
    # 데이터 크기
    n = len(X_train)
    
    # 독립변수의 갯수
    k = len(X_train.columns)
    
    # 수정된 결정 계수
    adj_r2 = 1-((1-r2) * (n-1) / (n-k-1))
    ```  
    
- 회귀 계수 확인: 각각의 독립 변수의 설명력 확인  
  - ndarray의 실수를 부동소수점으로 확인  
    ```py
    np.set_printoptions(supress = True)
    ```  
    
  - 회귀 모델에서 구한 회귀계수와 feature이름을 묶어 Series 자료형으로 만듦  
    ```py
    coef = pd.Series(data = np.round(reg.coef_,3), index = X.columns)
    
    print('y='+str(reg.intercept_)+'+')
    for i, c in zip(coef.index, coef.values):
        print('(' + str(c) + ')' + str(i))
    ```  
    
- 실제값과 예측값의 분포 차이를 시각화  
  ```py
  plt.figure(figsize = (6,6))
  plt.scatter(y_test, y_pred, s=80)
  plt.plot([5,50], [5,50], c='r', ls='--')
  plt.xlabel("Actual price($1,000s)")
  plt.ylabel("Predicted price")
  plt.grid()
  plt.show()
  ```  
  
## 보스턴 집값: 다중 선형 회귀 분석(스탯츠 모델)  
<div class="notice" markdown="1">
최소 제곱법으로 객체 생성, 학습, 예측, 평가를 진행 
</div>  
- 훈련 데이터로 학습 수행  

  ```py
  import statesmodel.api as sm
  
  X_train = sm,add_constant(X_trian)
  reg = sm.OLS(y_train, X_train).fit()
  ```  
  
- 검증 데이터로 예측 수행  
  ```py
  X_test = sm.add_constant(X_test)
  y_pred = reg.predict(X_test)
  ```  
  
- 평가 지표 값 확인  
  ```py
  reg.summary()
  ```  
  
## 당뇨병 데이터셋을 이용한 다중 선형 회귀 연습  
```py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
```  

- 데이터 수집  
  ```py
  from sklearn.datasets import load_diabetes
  
  diab = load_diabetes()
  ```  

- 데이터 준비  
  ```py
  from sklearn.model_selection import train_test_split
  
  X = diab.data
  y = diab.target
  ```  
  
- 모델 구축 
  - 회귀 모델 객체 생성   
    ```py
    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import mean_squared_error, r2_score
    import pandas as pd
    import numpy as np
    
    reg = LinearRegression()
    ```  
    
  - 학습 수행  
    ```py
    reg.fit(X_train, y_train)
    ```  
    
  - 회귀 계수 확인  
    ```py
    coef = pd.Series(data = reg.coef_, index = X.columns)
    ```  
    
  - 평가(검증)데이터로 예측 수행 → 예측 결과(y_pred)구하기  
    ```py
    y_pred = reg.predict(X_test)
    ```  
    
- 모델 평가  
  ```py
  mse = mean_squared_error(y_test, y_pred)
  rmse = np.sqrt(mse)
  
  r2 = r2_Score(y_test, y_pred)
  ```  
