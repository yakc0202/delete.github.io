---
title: "단순 선형 회귀"
date: 2021-07-21 -0400
categories: 
 - Regression
tags: 
 - [데이터 청년 캠퍼스, Regression]

toc: true

---
## 손실 함수 계산  
```py
import pandas as pd  
import matplotlib.pyplot as plt  
import numpy as np  
```  

- 학습률 0.5  
  ```py
  w1_list = [w for w in np.arange(-4, 4.5, 0.5)]  
  y = [1, 2, 3]  
  X = [1, 2, 3]  
  cost = []  
  for w1 in w1_list:  
      residual_sum = 0  
      for i in range(0,3):  
          residual = (y[i] - w1 * X[i])**2  
          residual_sum += residual  
      each_cost = residual_sum / len(y)  
      cost.append({w1: each_cost})  
  ```  
  
  * w와 cost와의 관계 시각화  
    ```py
    plt.figure(figsize=(5,5))  
    for i in range(len(cost)):  
        plt.scatter(cost[i].keys(), cost[i].values(), c='r', s=10)  
    ```  
    
- 학습률 0.1  
  ```py
  w1_list = [w for w in np.arange(-4, 4.5, 0.1)]  
  y = [1, 2, 3]  
  X = [1, 2, 3]  
  cost = []  
  for w1 in w1_list:  
      residual_sum = 0  
      for i in range(0,3):  
          residual = (y[i] - w1 * X[i])**2  
          residual_sum += residual  
      each_cost = residual_sum / len(y)  
      cost.append({w1: each_cost})  
  ```  
  
  * w와 cost와의 관계 시각화  
    ```py
    plt.figure(figsize=(5,5))  
    for i in range(len(cost)):  
        plt.scatter(cost[i].keys(), cost[i].values(), c='r', s=10)  
    ```  
    
- 학습률 2  
  ```py
  w1_list = [w for w in np.arange(-4, 4.5, 2)]  
  y = [1, 2, 3]  
  X = [1, 2, 3]  
  cost = []  
  for w1 in w1_list:  
      residual_sum = 0  
      for i in range(0,3):  
          residual = (y[i] - w1 * X[i])**2  
          residual_sum += residual  
      each_cost = residual_sum / len(y)  
      cost.append({w1: each_cost})  
  ```  
  
  * w와 cost와의 관계 시각화
    ```py
    plt.figure(figsize=(5,5))  
    for i in range(len(cost)):  
        plt.scatter(cost[i].keys(), cost[i].values(), c='r', s=10)  
    ```  
    
## 맥주 데이터를 활용한 단순 선형 회귀  
- 데이터 수집  
  ```py
  beer = pd.read_csv("./data/beer.csv")  
  ```  
  
- 데이터 탐색  
  ```py
  plt.figure(figsize=(5,5))  
  plt.scatter(beer['temperature'],beer['beer'])  
  plt.xlabel('temperature')  
  plt.ylabel('beer')  
  plt.grid()  
  plt.show()  
  ```  
  
  * 독립 변수, 종속 변수, 레코드 수 확인  
    ```py
    print(beer['temperature'])  
    print(beer['beer'])  
    print(len(beer))  
    ```  
    
- 데이터 준비 - 학습용 · 검증용 데이터 분리  
  ```py
  전체 데이터 중 80%는 학습용, 20%는 검증용으로 분리
  독립변수, 종속변수 데이터셋 준비
  X = np.array(beer['temperature']).reshape(-1,1)
  y = beer['beer']

  from sklearn.model_selection import train_test_split

  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)  
  ```  
  
- 모델 구축  
  * 모델 클래스 선택 후 인스턴스 객체 생성  
    ```py
    from sklearn.linear_model import LinearRegression  
    lr = LinearRegression()  
    ```  
    
  * 학습 수행
    ```py
    reg = lr.fit(X_train, y_train)  
    ```  
  * 계수 및 절편 확인
    ```py
    reg.coef_, reg.intercept_  
    ```  
    `_`속성은 학습을 통해 결정되는 속성{: .notice--primary}  
    
  * 회귀식  
    ```py
    print("y={:.2f}X + {:.3f}".format(reg.coef_[0],reg.intercept_))  
    ```  
    
  * 구축된 모델에서 예측 수행  
    ```py
    y_pred = reg.predict(X_test)  
    print(np.round(y_pred, 2))  
    ```  
    
- 모델 성능 평가  
  ```py
  from sklearn.metrics import mean_squared_error, r2_score  
  ```  
  
  * MSE  
    ```py
    mse = mean_squared_error(y_test, y_pred)  
    ```  
    MSE: metrics모듈의 mean_squared_error() 함수 사용{: .notice--primary}  
    
  * RMSE  
    ```py
    rmse = np.sqrt(mse)  
    ```  
    RMSE: numpy의 sqrt()함수 사용{: .notice--primary}  
    
  * 결정계수 R2  
    ```py  
    r2 = r2_score(y_test, y_pred)  
    ```  
    
- 시각화  
  * y = 0.697056X + 36.06 시각화  
    ```py
    plt.figure(figsize=(5,5))  
    xx=np.arange(beer['temperature'].min()-1,  
                 beer['temperature'].max()+1)  
    yy=reg.predict(xx.reshape(len(xx),1))  

    plt.plot(xx,yy,linestyle='--',color='red')  
    ```  
    
  * 수집한 데이터셋 시각화  
    ```py
    plt.scatter(beer['temperature'],beer['beer'])  
    plt.xlabel('temperature')  
    plt.ylabel('beer')  
    plt.grid()  
    plt.show()  
    ```  
    
## 나이, 키의 관계 회귀 분석  
- 데이터 생성 · 수집  
  ```py
  data_df = pd.read_csv("data/age_height.csv")  
  ```  
  
- 데이터 탐색  
  ```py
  plt.figure(figsize = (5,5))  
  plt.scatter(data_df['age(X)'], data_df['height(T)']
  plt.xlabel('age(X)')
  plt.ylabel('height(T)')
  plt.grid()
  ```  
  
- 데이터 준비 - 학습용 · 검증용 데이터 분리  
  ```py
  # 전체 데이터 중 80%는 학습용, 20%는 검증용으로 분리
  
  X = np.array(data_df['age(X)']).reshape(-1,1)
  y = data_df['height(T)']
  
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)
  ```  

- 모델 구축 및 예측  
  * 모델 객체 생성 및 학습  
    ```py
    lr = LinearRegression()
    
    reg.fit(X_train, y_train)
    ```  
    
  * 예측 수행  
    ```py
    y_pred = reg.predict(X_test)
    ```  
    
- 모델 성능 평가  
  * MSE
    ```py
    mse = mean_squared_error(y_test, y_pred)
    ```  
    
  * RMSE  
    ```py
    rmse = np.sqrt(mse)
    ``` 
  
  * 결정 계수 R2  
    ```py
    r2 = r2_score(y_test, y_pred)  
    ```  
    
  * 회귀식  
    ```py
    print("y = {:.2f}X + {:.3f}".format(reg.coef_[0], reg.intercept_))
    ```  
    
- 시각화  
  * y = 0.697056X + 36.06 시각화  
    ```py
    plt.figure(figsize = (5,5))
    plt.scatter(data_df['age(X)'], data_df['height(T)'], color = 'red')
    
    xx = np.arange(data_df['age(X)'].min() - 1,
                   data_df['height(T)'].max() + 1)
    yy = reg.predict(xx.reshape(len(xx), 1)
    plt.plot(xx, yy, linestyle = '--', color= 'g')
    plt.gird()
    plt.show()
    ```  
    
  * 나이, 키 데이터 실제 데이터 및 회귀식 
    ```py
    plt.scatter(data_df['age(X)'], data_df['height(T)'])
    plt.xlabel('age(X)')
    plt.ylabel('height(T)')
    plt.grid()
    plt.show()
    ```  

## 스탯츠 모델에서 단순 선형 회귀  
- 스탯츠 모델 import  
  ```py
  import statsmodels.api as sm
  ```  
  
- 맥주 데이터 생성
  ```py
  beer = pd.read_csv('data/beer.csv')
  ```  
  
- 데이터 준비  
  ```py
  X = np.array(beer['temperature']).reshape(-1,1)
  y = beer['beer']
  
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)
  ```  
  
- 스탯츠 모델  
  ```py  
  X_train = sm.add_constant(X_train)
  X_test = sm.add_constant(X_test)
  
  lr = sm.OLS(y_train, X_train)
  
  reg = lr.fit()
  ```  
  
- 성능 평가  
  ```py
  reg.summar()
  ```  
  
## 보스턴 집값 선형 회귀  
- 데이터 수집  
  ```py
  from sklearn.datasets import load_boston
  
  boston = load_boston()
  ```  
  
- 독립 변수(RM), 종속 변수를 골라내고, DataFrame으로 변환  
  ```py
  df = pd.DataFrame(boston.data, colums = boston.feature_names)
  
  X = pd.DataFrame(df['RM'])
  y = boston.target
  ```  
  
- 데이터 탐색  
  ```py
  plt.figure(figsize = (5,5))
  plt.scatter(X, y)
  plt.show()
  ```  
  
- 학습용 · 검증용 데이터 분리  
  ```py
  # 조건: 학습 7, 검증 3
  # seed = 1로 고정
  from sklearn.model_selection import train_test_split
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)
  ```
  
- 모델 구축  
  ```py
  from sklearn.linear_model import LinearRegression
  
  reg = LinearRegression().fit(X_trian, y_train)
  print("y = {:,2f}X + ({:.3f})".format(reg.coef_[0], reg.intercept_))
  ```  

- 모델 평가  
  ```py
  y_pred = reg.predict(X_test)
  
  from skklearn.metrics import mean_squared_error, r2_score
  
  mse = mean_squared_error(y_test, y_pred)
  rmse = np.sqrt(mse)
  r2 = r2_score(y_test, y_pred)
  ```  

- 시각화  
  ```py
  plt.figure(figsize = (5,5))
  plt.scatter(X, y, color = 'red', s=5)
  
  xx = np.linespace(X.min), X.max())
  yy = reg.predict(xx.reshape(len(xx),1))
  plt.plot(xx, yy, linestyle = '--', color = 'g')
  
  plt.xlabel(" $ of rooms')
  plt.ylabel("price")
  plt.grid()
  plt.show()
  ```  
